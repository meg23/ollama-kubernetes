
image:
  repository: ollama/ollama
  pullPolicy: IfNotPresent
  tag: "0.6.2"

replicaCount: 1

llm:
  models: ["phi4", "deepseek-r1:14b"]

persistentVolume:
  enabled: false  # Use emptyDir instead of PVC
  storageClass: ""
  accessModes: []
  size: ""
  claimName: ""

resources:
  limits:
    cpu: 2
    memory: 4Gi
  requests:
    cpu: 500m
    memory: 512Mi

service:
  type: ClusterIP
  port: 11434

livenessProbe:
  failureThreshold: 3
  periodSeconds: 30
  timeoutSeconds: 15
  httpGet:
    path: /
    port: http
readinessProbe:
  failureThreshold: 3
  periodSeconds: 30
  timeoutSeconds: 15
  httpGet:
    path: /
    port: http

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80

nodeSelector: {}
tolerations: []
affinity: {}

############ Configuration for Ollama WebUI ############

ui:
  enabled: true
  replicaCount: 1

  image:
    repository: ghcr.io/open-webui/open-webui
    pullPolicy: IfNotPresent
    tag: "latest"

  pipelineImage:
    repository: ghcr.io/open-webui/pipelines
    pullPolicy: IfNotPresent
    tag: "latest"

  service:
    type: ClusterIP
    port: 80

  persistentVolume:
    enabled: false  # Use emptyDir instead of PVC
    storageClass: ""
    accessModes: []
    size: ""
    claimName: ""

  ingress:
    enabled: false
    className: ""
    annotations: {}
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []

  nodeSelector: {}
  tolerations: []
  affinity: {}

